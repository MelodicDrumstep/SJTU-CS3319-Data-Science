# 数据科学基础第二次作业实验报告

## 实验概述

本次实验是用深度学习模型做情绪识别， 我实现了对应训练框架， 并使用 `MLP`, `RNN`, `LSTM` 三个模型开展了该任务。 我还尝试了 `CNN`， 这部分代码也留存在最终代码中， 但 `CNN` 模型相关代码一直有 bug， 因此没有全面完成基于它的情绪识别。

## 实验细节

### 数据预处理

这部分代码请见 [src/data_loader.py](src/data_loader.py) 和 [src/emotion_recognition.py](src/emotion_recognition.py)。

在 `load_seed_data_npy` 函数中， 我将数据从 npy 文件中加载到 numpy 数组中， 然后在 `run_cross_subject_validation` 函数中， 我遵循跨被试留一交叉验证的规则划分训练集和测试集， 将数据进行维度调整并转化为了 pytorch tensor 类型。

### 模型结构设计

- **MLP**
  
```
  +-----------------------+
  |    输入层 (大小: 310)  |
  +-----------------------+
              |
       +---------------------+
       | 第一隐藏层           |
       | FC -> ReLU -> Dropout|
       | (256 神经元)         |
       +---------------------+
              |
       +---------------------+
       | 第二隐藏层           |
       | FC -> ReLU -> Dropout|
       | (128 神经元)         |
       +---------------------+
              |
       +---------------------+
       | 第三隐藏层           |
       | FC -> ReLU -> Dropout|
       | (64 神经元)          |
       +---------------------+
              |
       +-------------+
       |  输出层 (3)  |
       +-------------+
```

- 输入大小: 310 (作为应用线性化的 62 个通道和 5 个频段)
- 隐藏层:
    - 第一层: 72 个神经元，ReLU 激活函数，Dropout 比例为 0.3。
    - 第二层: 36 个神经元，ReLU 激活函数，Dropout 比例为 0.3。
    - 第三层: 18 个神经元，ReLU 激活函数，Dropout 比例为 0.3。
  
- 输出层: 3 个神经元，对应积极、消极和中性三种情绪状态。
  
- **RNN**
  
  ```
  +------------------------+
  |    输入层 (大小: 62 x 5) |
  +------------------------+
               |
       +----------------------+
       | RNN 层 (2 层, tanh)   |
       | 隐藏单元数: 8         |
       +----------------------+
               |
       +----------------------+
       | 全连接层 (输出 3 类别) |
       +----------------------+
  ```

  - **输入大小**: 62 个通道的 5 个频段。
  - **RNN 层**:
    - 使用了 6 RNN，隐藏单元数为 8。
    - 每一层 RNN 的非线性激活函数使用 `tanh`，以增强模型的非线性表达能力。
    - 输出包含每个时间步的隐藏状态，取最后一个时间步的隐藏状态用于最终分类。
  - **全连接层**: 将 RNN 层最后一个时间步的输出连接到全连接层，输出 3 个神经元，对应三种情绪状态。

- **LSTM (Long Short-Term Memory)**
  
  ```
  +------------------------+
  |    输入层 (大小: 62 x 5) |
  +------------------------+
               |
       +-----------------------+
       | LSTM 层 (5 层)        |
       | 隐藏单元数: 8          |
       +-----------------------+
               |
       +-----------------------+
       | 全连接层 (输出 3 类别)  |
       +-----------------------+
  ```

  - **输入大小**: 62 个通道的 5 个频段。
  - **LSTM 层**:
    - 使用了 5 层的 LSTM，隐藏单元数为 8。
  - **全连接层**: 将 LSTM 层最后一个时间步的输出连接到全连接层，输出 3 个神经元，对应三种情绪状态。
   
注:   以上模型中的超参数通过网格搜索确定， 在下方 "超参设置" 部分提及。

### 训练及测试设置

- 训练过程中使用 CrossEntropyLoss 作为损失函数
- 使用 Adam 作为选择的优化器，应用 0.0001 的学习率
- 每个训练进行 30 个 epoch
- 对于每次跨被试的留一交叉验证，记录测试集的准确率

### 超参设置

对于以下这些超参数， 我均通过网格搜索来确定:

+ MLP 每个隐藏层的神经元个数

+ MLP 每个隐藏层的 drop out 比例

+ RNN 隐藏层的神经元个数

+ RNN 的层数

+ LSTM 隐藏层的神经元个数

+ LSTM 的层数

按理说 MLP 也可以网格搜索一下层数， 不过我这里没有这样做。

我网格搜索的函数是 (src/emotion_recognition.py)[src/emotion_recognition.py] 中的 `grid_search_MLP`， `grid_search_RNN` 和 `grid_search_LSTM`

## 实验结果

| 模型 | 平均准确率 | 标准差 |
|-----------|---------------|---------|
| MLP       | 0.46 | 0.12 |
| RNN       | 0.47| 0.10 |
| LSTM      | 0.51 | 0.13 |

## 实验结果分析

三种模型在 SEED 数据集上进行跨被试留一交叉验证的平均识别准确率都在 50% 左右， 标准差都在 0.10 左右。  

对于识别准确率不高的原因， 我初步认为是数据集本身较小， 且数据本身不便于训练。 在课前和老师交流后， 老师说跨被试留一交叉验证能有 50% 的识别准确率已经差不多了。 因此可能还有一个原因是跨被试留一交叉验证本身就对结果更加苛刻。

总体而言，三种模型的准确率都未能达到特别高的水平，主要原因在于数据集的规模较小且存在较大的个体差异，导致模型难以泛化。此外，跨被试留一交叉验证的苛刻性也使得模型很难在不同被试之间取得一致的表现。
